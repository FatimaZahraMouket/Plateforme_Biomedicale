{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c12dfb34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in c:\\users\\hp\\anaconda3\\lib\\site-packages (2.15.0)\n",
      "Requirement already satisfied: tensorflow-intel==2.15.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from tensorflow) (2.15.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (2.0.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=23.5.26 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (23.5.26)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (0.5.4)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (0.2.0)\n",
      "Requirement already satisfied: h5py>=2.9.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (3.7.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (16.0.6)\n",
      "Requirement already satisfied: ml-dtypes~=0.2.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (0.2.0)\n",
      "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (1.24.3)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (3.3.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\hp\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (23.0)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (4.23.4)\n",
      "Requirement already satisfied: setuptools in c:\\users\\hp\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (67.8.0)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (2.4.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (4.6.3)\n",
      "Requirement already satisfied: wrapt<1.15,>=1.11.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (1.14.1)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (0.31.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (1.60.0)\n",
      "Requirement already satisfied: tensorboard<2.16,>=2.15 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (2.15.1)\n",
      "Requirement already satisfied: tensorflow-estimator<2.16,>=2.15.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (2.15.0)\n",
      "Collecting keras<2.16,>=2.15.0 (from tensorflow-intel==2.15.0->tensorflow)\n",
      "  Using cached keras-2.15.0-py3-none-any.whl (1.7 MB)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from astunparse>=1.6.0->tensorflow-intel==2.15.0->tensorflow) (0.38.4)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (2.25.2)\n",
      "Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (1.2.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (3.4.1)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (2.29.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (2.2.3)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (5.3.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (0.2.8)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (4.9)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (1.3.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (2023.11.17)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (2.1.1)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (3.2.2)\n",
      "Installing collected packages: keras\n",
      "  Attempting uninstall: keras\n",
      "    Found existing installation: keras 2.6.0\n",
      "    Uninstalling keras-2.6.0:\n",
      "      Successfully uninstalled keras-2.6.0\n",
      "Successfully installed keras-2.15.0\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow\n",
    "!pip install keras\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c1c44e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pika\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense\n",
    "\n",
    "\n",
    "\n",
    "import pickle\n",
    "\n",
    "EXCHANGE_NAME = 'prediction_exchangesa'\n",
    "QUEUE_NAME = 'lstm-result-queue'\n",
    "MODEL_FILE_PATH = 'lstm_model.pkl'\n",
    "\n",
    "def train_and_save_lstm(df_train):\n",
    "    # Normalize the data\n",
    "    normalized_data = (df_train - df_train.min()) / (df_train.max() - df_train.min())\n",
    "\n",
    "    # Convert the DataFrame to a numpy array\n",
    "    training_data = normalized_data.values\n",
    "\n",
    "    # Split the data into input and output\n",
    "    x_train, y_train = [], []\n",
    "    for i in range(len(training_data) - 10):\n",
    "        x_train.append(training_data[i:i+9])  # Use the last 9 values to predict the next one\n",
    "        y_train.append(training_data[i+10])  # Predict the 10th value\n",
    "\n",
    "    x_train, y_train = np.array(x_train), np.array(y_train)\n",
    "\n",
    "    # Reshape the data for LSTM input\n",
    "    x_train = np.reshape(x_train, (x_train.shape[0], x_train.shape[1], 1))\n",
    "\n",
    "    # Build the LSTM model\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(units=50, activation='relu', input_shape=(x_train.shape[1], 1)))\n",
    "    model.add(Dense(units=1))\n",
    "    model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "\n",
    "    # Train the model\n",
    "    model.fit(x_train, y_train, epochs=50, batch_size=1)\n",
    "\n",
    "    # Save the trained model to a file\n",
    "    model.save(MODEL_FILE_PATH)\n",
    "\n",
    "def load_and_predict_lstm(df_forecast):\n",
    "    # Load the trained model from the file\n",
    "    model = Sequential()\n",
    "    model = model.load(MODEL_FILE_PATH)\n",
    "\n",
    "    # Normalize the forecast data\n",
    "    normalized_forecast = (df_forecast - df_forecast.min()) / (df_forecast.max() - df_forecast.min())\n",
    "\n",
    "    # Convert the DataFrame to a numpy array\n",
    "    forecast_data = normalized_forecast.values\n",
    "\n",
    "    # Prepare data for forecasting\n",
    "    x_forecast = forecast_data[-9:]  # Use the last 9 values for forecasting\n",
    "    x_forecast = np.reshape(x_forecast, (1, x_forecast.shape[0], 1))\n",
    "\n",
    "    # Make predictions\n",
    "    predicted_value = model.predict(x_forecast)\n",
    "\n",
    "    # Denormalize the predicted value\n",
    "    predicted_value = predicted_value * (df_forecast.max() - df_forecast.min()) + df_forecast.min()\n",
    "\n",
    "    return predicted_value.flatten()\n",
    "\n",
    "def callback(ch, method, properties, body):\n",
    "    message = body.decode('latin-1')\n",
    "    print(f\"Received: {message}\")\n",
    "\n",
    "    try:\n",
    "        json_object = json.loads(message)\n",
    "        start_date = json_object['startDate']\n",
    "        csv_path = json_object['temperatureData']\n",
    "\n",
    "        # Read only the necessary columns\n",
    "        df1 = pd.read_csv(\"lettuce_dataset.csv\", usecols=['Date', 'Temperature'], encoding='ISO-8859-1')\n",
    "\n",
    "        # Convert 'Date' to datetime\n",
    "        df1['Date'] = pd.to_datetime(df1['Date'], errors='coerce')\n",
    "\n",
    "        # Drop rows with missing dates\n",
    "        df1 = df1.dropna(subset=['Date'])\n",
    "\n",
    "        # Set 'Date' as the index\n",
    "        df1.set_index('Date', inplace=True)\n",
    "\n",
    "        # Train and save the LSTM model\n",
    "        train_and_save_lstm(df1)\n",
    "\n",
    "        # Convert the 'date' column to datetime format\n",
    "        df_forecast = pd.DataFrame(csv_path)\n",
    "        df_forecast['date'] = pd.to_datetime(df_forecast['date'], format='%Y-%m-%d')\n",
    "\n",
    "        # Set 'date' as the index\n",
    "        df_forecast.set_index('date', inplace=True)  # Corrected line using 'date' column\n",
    "\n",
    "        # Load the trained model and make predictions\n",
    "        forecast_values = load_and_predict_lstm(df_forecast)\n",
    "\n",
    "        prediction_dict = [{'date': str(key), 'temperature': value} for key, value in zip(df_forecast.index, forecast_values)]\n",
    "\n",
    "        connection = pika.BlockingConnection(pika.ConnectionParameters('localhost'))\n",
    "        channel = connection.channel()\n",
    "        channel.exchange_declare(exchange=EXCHANGE_NAME, exchange_type='fanout', durable=True)\n",
    "        channel.queue_declare(queue=QUEUE_NAME, durable=True)\n",
    "        channel.queue_bind(exchange=EXCHANGE_NAME, queue=QUEUE_NAME)\n",
    "\n",
    "        print(\"---------\")\n",
    "\n",
    "        prediction_message = json.dumps({\"prediction\": prediction_dict})\n",
    "        print(f\"Number of elements in prediction_dict: {prediction_dict}\")\n",
    "\n",
    "        channel.basic_publish(exchange=EXCHANGE_NAME, routing_key='', body=prediction_message)\n",
    "        connection.close()\n",
    "\n",
    "    except KeyError as e:\n",
    "        print(f\"Error processing message: {e}\")\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    connection = pika.BlockingConnection(pika.ConnectionParameters('localhost'))\n",
    "    channel = connection.channel()\n",
    "    channel.exchange_declare(exchange=EXCHANGE_NAME, exchange_type='fanout', durable=True)\n",
    "    channel.queue_declare(queue=QUEUE_NAME, durable=True)\n",
    "    channel.queue_bind(exchange=EXCHANGE_NAME, queue=QUEUE_NAME)\n",
    "    channel.basic_consume(queue=QUEUE_NAME, on_message_callback=callback, auto_ack=True)\n",
    "    print('Waiting for messages. To exit press CTRL+C')\n",
    "    channel.start_consuming()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bfc2844",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
